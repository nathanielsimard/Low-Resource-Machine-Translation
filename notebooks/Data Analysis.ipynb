{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import subprocess\n",
    "import torch\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to read and write text/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_size(stream):\n",
    "    result = sum(1 for _ in stream)\n",
    "    stream.seek(0)\n",
    "    return result\n",
    "\n",
    "def read_token_file(file_name: str):\n",
    "    out = []\n",
    "    with open(file_name, 'r') as stream:\n",
    "            file_size = get_stream_size(stream)\n",
    "            for line in stream:\n",
    "                tokens = line.strip().split()\n",
    "                out.append(tokens)\n",
    "    return out\n",
    "\n",
    "def read_text_file(file_name: str):\n",
    "    out = []\n",
    "    with open(file_name, 'r') as stream:\n",
    "            file_size = get_stream_size(stream)\n",
    "            for line in stream:\n",
    "                tokens = line.strip()\n",
    "                out.append(tokens)\n",
    "    return out\n",
    "\n",
    "def write_text_from_tokens(tokens, output_file):\n",
    "    with open(output_file, 'w+') as out_stream:\n",
    "        for token in tokens:\n",
    "            out_stream.write(' '.join(token) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Information Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class corpus_information():\n",
    "    def __init__(self, corpus, language, dataset_name, n_most_common=20, remove_punctuation=False):\n",
    "        self.corpus = corpus\n",
    "        self.language = language\n",
    "        self.dataset_name = dataset_name\n",
    "        self.n_most_common = n_most_common\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.counter = self._counter_corpus()\n",
    "        self.count_words = self._count_words()\n",
    "        self.count_unique_words = self._count_unique_words()\n",
    "        self.most_common_words = self._most_common_words()\n",
    "        self.count_sequences = self._count_sequences()\n",
    "        self.sequences_length = self._sequences_length()\n",
    "        self.max_sequences_length = self._max_sequences_length()\n",
    "        self.mean_sequences_length = self._mean_sequences_length()\n",
    "\n",
    "    def _counter_corpus(self):\n",
    "        reg = r\"[\\w]+|[.,!?;:'\\'()\\[\\]{}\\\"]\"\n",
    "        if self.remove_punctuation:\n",
    "            reg = r'\\w+'\n",
    "        return collections.Counter([word for sentence in self.corpus for word in re.findall(reg, sentence)])\n",
    "    \n",
    "    def _count_words(self):\n",
    "        reg = r\"[\\w]+|[.,!?;:'()\\[\\]{}\\\"]\"\n",
    "        if self.remove_punctuation:\n",
    "            reg = r'\\w+'\n",
    "        return len([word for sentence in self.corpus for word in re.findall(reg, sentence)])\n",
    "\n",
    "    def _count_unique_words(self):\n",
    "        return len(self.counter)\n",
    "    \n",
    "    def _most_common_words(self):\n",
    "        return list(zip(*self.counter.most_common(self.n_most_common)))[0]\n",
    "    \n",
    "    def _count_sequences(self):\n",
    "        return len(self.corpus)\n",
    "    \n",
    "    def _sequences_length(self):\n",
    "        return [len(sentence) for sentence in self.corpus]\n",
    "    \n",
    "    def _max_sequences_length(self):\n",
    "        return np.max(self.sequences_length)\n",
    "    \n",
    "    def _mean_sequences_length(self):\n",
    "        return np.mean(self.sequences_length)\n",
    "    \n",
    "    def show_informations(self):\n",
    "        print(self.dataset_name+': ')\n",
    "        print(f'{self.count_words} {self.language} words.')\n",
    "        print(f'{self.count_unique_words} unique {self.language} words.')\n",
    "        print(f'{self.n_most_common} Most common words in the {self.dataset_name} :')\n",
    "        print('\"' + '\" \"'.join(self.most_common_words) + '\"')\n",
    "        print(f'{self.count_sequences} sequences in {self.dataset_name}')\n",
    "        print(f'The longest sequence as a length of {self.max_sequences_length}.')\n",
    "        print('The mean sequence length is {:.2f}.'.format(self.mean_sequences_length))\n",
    "        print('\\n')    \n",
    "        \n",
    "    def histogram_sequences_length(self, output_path,  bin_number=100):\n",
    "        plt.hist(self.sequences_length, bins=bin_number)\n",
    "        plt.title(f\"Sequences length of {self.dataset_name}\")\n",
    "        plt.xlabel(\"Sequence length\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenized alligned texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_token_file = read_token_file('../data/train.lang1')\n",
    "fr_token_file = read_token_file('../data/train.lang2')\n",
    "en_aligned_text_file = [' '.join(word) for word in en_token_file]\n",
    "fr_aligned_text_file = [' '.join(word) for word in fr_token_file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligned texts information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Aligned DataSet: \n",
      "205374 English words.\n",
      "13524 unique English words.\n",
      "20 Most common words in the English Aligned DataSet :\n",
      "\"the\" \"of\" \"to\" \"and\" \"in\" \"a\" \"is\" \"that\" \"i\" \"it\" \"we\" \"this\" \"for\" \"on\" \"be\" \"'\" \"are\" \"not\" \"have\" \"s\"\n",
      "11000 sequences in English Aligned DataSet\n",
      "The longest sequence as a length of 512.\n",
      "The mean sequence length is 105.17.\n",
      "\n",
      "\n",
      "French Aligned DataSet: \n",
      "260371 French words.\n",
      "17960 unique French words.\n",
      "20 Most common words in the French Aligned DataSet :\n",
      "\".\" \"'\" \"de\" \",\" \"la\" \"l\" \"et\" \"le\" \"à\" \"les\" \"des\" \"que\" \"d\" \"est\" \"en\" \"un\" \"une\" \"du\" \"pour\" \"a\"\n",
      "11000 sequences in French Aligned DataSet\n",
      "The longest sequence as a length of 562.\n",
      "The mean sequence length is 123.90.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "en_aligned_info = corpus_information(en_aligned_text_file, 'English', 'English Aligned DataSet')\n",
    "fr_aligned_info = corpus_information(fr_aligned_text_file, 'French', 'French Aligned DataSet')\n",
    "en_aligned_info.show_informations()\n",
    "fr_aligned_info.show_informations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save sequences length histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_aligned_info.histogram_sequences_length('data_set_analysis/en_aligned_sequence_len_histogram.png')\n",
    "fr_aligned_info.histogram_sequences_length('data_set_analysis/fr_aligned_sequence_len_histogram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not tokenized and not alligned texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_text_file = read_text_file('../data/unaligned.en')\n",
    "fr_text_file = read_text_file('../data/unaligned.fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unaligned text information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Unaligned DataSet: \n",
      "9795581 English words.\n",
      "67571 unique English words.\n",
      "20 Most common words in the English Unaligned DataSet :\n",
      "\"the\" \".\" \",\" \"to\" \"of\" \"and\" \"in\" \"a\" \"is\" \"that\" \"I\" \"for\" \"'\" \"this\" \"be\" \"we\" \"on\" \"it\" \"are\" \"have\"\n",
      "474000 sequences in English Unaligned DataSet\n",
      "The longest sequence as a length of 788.\n",
      "The mean sequence length is 106.46.\n",
      "\n",
      "\n",
      "French Unaligned DataSet: \n",
      "11158476 French words.\n",
      "86040 unique French words.\n",
      "20 Most common words in the French Unaligned DataSet :\n",
      "\".\" \"'\" \"de\" \",\" \"la\" \"l\" \"et\" \"le\" \"à\" \"les\" \"des\" \"que\" \"d\" \"est\" \"en\" \"un\" \"une\" \"du\" \"pour\" \"nous\"\n",
      "474000 sequences in French Unaligned DataSet\n",
      "The longest sequence as a length of 969.\n",
      "The mean sequence length is 119.91.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "en_unaligned_info = corpus_information(en_text_file, 'English', 'English Unaligned DataSet')\n",
    "fr_unaligned_info = corpus_information(fr_text_file, 'French', 'French Unaligned DataSet')\n",
    "en_unaligned_info.show_informations()\n",
    "fr_unaligned_info.show_informations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save sequences length histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_unaligned_info.histogram_sequences_length('data_set_analysis/en_unaligned_sequence_len_histogram.png')\n",
    "fr_unaligned_info.histogram_sequences_length('data_set_analysis/fr_unaligned_sequence_len_histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
